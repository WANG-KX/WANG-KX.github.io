---
layout: post
title: Nvidia Alpamayo 及其他
date: 2026-01-11
tags: [周报, Nvidia]
excerpt: 2026 第 2 周
---

本周 nvidia 发布并且开源了一个自动驾驶 VLA 模型，[Alpamayo](https://nvidianews.nvidia.com/news/alpamayo-autonomous-vehicle-development)，并且在 CES 上展现了其在真实道路环境上的驾驶的驾驶表现。根据公开出来的视频，这个模型在复杂城市道路上也能比较流畅的运行，但是仍然有一些安全接管。该项目一出，互联网上就有了非常多的讨论，包括是否会挑战 tesla 多年建立的自动驾驶护城河，Elon 以及 Tesla Ashok 也公开回应了 NV 的这套系统。因为 NV 没有大规模展现系统能力，且缺少一镜到底的视频，我更倾向于认为这个系统能力是一般水平。

从公开的技术报告来说，Alpamayo 是一个比较标准的 VLA 框架，借鉴了很多具身领域的技术。通过对齐 CoT 的推理以及系统输出的轨迹，该模型可以在训练部署的时候，显式监督因果逻辑链。技术报告也详细说明了应该如何标注数据，避免系统出现因果混淆，避免流于表面。看起来这套系统标准的 VLA 框架下的自动驾驶范例，学术界一定会收益良多，可以以此为起点做很多的探索（更何况 NV 还开源了一个闭环仿真系统，刷榜的人有福了）。

从开源模型的效果来说，效果也不及预期。一方面，虽然技术报告中多次强调因果一致性，但是实测下来，很多的驾驶场景，CoT 与轨迹输出之间没有严格的匹配起来。另一方面，展现的场景中也很难看出 VLA 的优势所在，一个一般的端到端模型应该也是完全可以处理的。开源模型到 NV 实际路测之间应该是有巨大鸿沟的，更不用想 NV 与 Tesla 之间的差距。

我比较认可 VLA，CoT 这样的技术框架是通向开放世界 L4 自动驾驶的重要模块。主要的原因是这样的系统可以借鉴互联网数据，从而通过 few-shot learning 的方式提升数据利用效率，逐步消除自动驾驶的长尾问题。举例来说，VLA 可以通过其预训练过程建立各种障碍物是不能碰撞的概念，从而提升自动驾驶场景中的安全性。通过对问题数据的 CoT 标注，我们就可以重新训练 VLA 模型，让它能够知其所以然，从而知其然。

短期来看，tesla 的系统仍然是绝对领先的，它有公开可测的版本，积累了大量的长尾问题，并且仍然以一个非常高的速度在持续积累。从长远来看，随着 VLM 以及具身技术的发展，更多公司可以拥有一个还不错的自动驾驶版本。可能未来的自动驾驶真的就类似苹果与安卓的差别，各种自动驾驶版本之间的差异可能是长尾问题的处理能力。个细小却重要的区别，决定了消费者对他们的认知，以及商业化中的利润比例。

# 其他

- 论文 *One Sample to Rule Them All: Extreme Data Efficiency in RL Scaling* 以及 *LIMR: Less is More for RL Scaling* 主要讨论 LLM RL 过程中的数据差异，主要强调 RL 过程中数据的质量远比数量重要。通过构造小而精的数据，我们可以大幅提升模型（尤其是小模型）能力。
- 项目 *How Much 3D Do Video Foundation Models Encode?*，[https://vidfm-3d-probe.github.io/](https://vidfm-3d-probe.github.io/)，证明了 Video Diffuion 确实学习了大量的场景几何信息。一方面，直接证明了从 diffusion 网络 finetune 出深度的合理性，另一方面，也给大家拓宽了思路，diffusion 确实是一个非常好的 3D 信息预训练任务。
- *Large Video Planner Enables Generalizable Robot Control* 另一个 video diffusion 的下游应用工作。看起来还是比较粗糙的，只能算是一个概念验证，但是不可忽视地指出了 video diffusion 模型是一个包含丰富信息的富矿，值得各种挖掘。
