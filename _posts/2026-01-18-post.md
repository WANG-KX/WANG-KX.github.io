---
layout: post
title: ImageNet 及其他
date: 2026-01-18
tags: [周报]
excerpt: 2026 第 3 周
---

本周看了李飞飞的自传 *我看见的世界*，其中花了比较大的篇幅讲述了 ImageNet 的故事（不然呢，这个也是她的成名作）。

之前我还不懂事，对于李飞飞没有足够的尊重，总认为她的贡献就是一个数据集，没有很多的技术含量，也不是诸多算法的发明人。在阅读这本书之后，了解了这个数据集的前因后果，以及在过程中遇到的挑战、怀疑，我非常佩服她。

首先说这个数据集，李飞飞并非一个典型的计算机科学家，她本科以及博士期间的研究经历与神经科学，脑科学，都有交叉，主要集中在认知层面。博士期间她意识到数据集的规模对于算法的重要性，一个算法的能力需要足够大的数据集来支撑。2004 年，她做了一个数据集，Caltech 101，有 9000 张图像，当时已经是世界上最大的分类数据集了。在博士毕业后，她偶然知道一个叫做 WorldNet 的项目，这个项目统计了世界上的各种概念以及其关系，衍生有一个 ImageNet 用于增加概念的图像信息。WorldNet 中的 ImageNet 项目实际上是不成功的，但是激发了李飞飞的兴趣，她想把这个概念借鉴过来，做一个上万类别的数据集。

做数据集的时候，她刚刚在普林斯顿做 AP，还有很多的考核压力。跟同行交流，大多数也不是很能理解她的东西，大家认可数据很重要，但是不认可学术界需要这么大的数据集。凭借自己的信念，她和自己的第一个学生，邓嘉，开始了数据标注的工作。凭借各种工程上的优化以及当时众包平台的发展，这个数据集才渐渐被做出来。数据集做出来之后，也并没有立刻取得大家的关注，李飞飞又进而在会议上各种宣传，分发带有 ImageNet 标志的纪念品，去不同的学校给 talk，并且举办每年的分类比赛（头两年效果也比较一般）。直到 2012 年，alexnet 在 ImageNet 上展现了深度学习的巨大优势，ImageNet 才跟随深度学习的技术被大家广泛使用。

如果没有李飞飞之前的研究经历，没有 Google 搜索，Amazon 众包平台，没有 Hinton 对深度学习的执着探索，很难说当下的深度学习会是什么样的形态。可以说 ImageNet 奠定了深度学习前几年的发展方向，大家都已分类任务为最通用的任务来探索网络架构以及学习范式。

# 其他

- *VLM4VLA Revisiting Vision-Language Models in Vision-Language-Action Models*，VLM 预训练对 VLA 必要但不充分，其通用能力无法全面预测 VLA 性能，VLA 需超越现有 VLM 能力的特殊表征。具身辅助任务微调无法提升 VLA 性能，现有具身 VQA 任务与下游操控需求不匹配。VLM 的视觉编码器是 VLA 性能的主要瓶颈，向视觉模块注入控制相关监督可稳定提升性能，需弥合 VLM 预训练目标与具身动作规划需求的域差。
